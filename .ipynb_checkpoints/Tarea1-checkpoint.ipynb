{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea 1 de Aprendizaje de Maquinas\n",
    "## Nicolás Alarcón 201473522-7\n",
    "## Gabriel Valenzuela 201473505-7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pregunta 1:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>910</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      price  bedrooms  bathrooms  sqft_living  sqft_lot  floors  waterfront  \\\n",
       "0  221900.0         3       1.00         1180      5650     1.0           0   \n",
       "1  538000.0         3       2.25         2570      7242     2.0           0   \n",
       "2  180000.0         2       1.00          770     10000     1.0           0   \n",
       "3  604000.0         4       3.00         1960      5000     1.0           0   \n",
       "4  510000.0         3       2.00         1680      8080     1.0           0   \n",
       "\n",
       "   view  condition  grade  sqft_above  sqft_basement  yr_built  yr_renovated  \\\n",
       "0     0          3      7        1180              0      1955             0   \n",
       "1     0          3      7        2170            400      1951          1991   \n",
       "2     0          3      6         770              0      1933             0   \n",
       "3     0          5      7        1050            910      1965             0   \n",
       "4     0          3      8        1680              0      1987             0   \n",
       "\n",
       "       lat     long  sqft_living15  sqft_lot15  \n",
       "0  47.5112 -122.257           1340        5650  \n",
       "1  47.7210 -122.319           1690        7639  \n",
       "2  47.7379 -122.233           2720        8062  \n",
       "3  47.5208 -122.393           1360        5000  \n",
       "4  47.6168 -122.045           1800        7503  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "df = pd.read_csv(\"kc_house_data.csv\")\n",
    "df.drop(['id','date','zipcode',],axis=1,inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo de la linea 4 es que las columnas 'id', 'date' y 'zipcode' sean removidas de la tabla"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21613 entries, 0 to 21612\n",
      "Data columns (total 18 columns):\n",
      "price            21613 non-null float64\n",
      "bedrooms         21613 non-null int64\n",
      "bathrooms        21613 non-null float64\n",
      "sqft_living      21613 non-null int64\n",
      "sqft_lot         21613 non-null int64\n",
      "floors           21613 non-null float64\n",
      "waterfront       21613 non-null int64\n",
      "view             21613 non-null int64\n",
      "condition        21613 non-null int64\n",
      "grade            21613 non-null int64\n",
      "sqft_above       21613 non-null int64\n",
      "sqft_basement    21613 non-null int64\n",
      "yr_built         21613 non-null int64\n",
      "yr_renovated     21613 non-null int64\n",
      "lat              21613 non-null float64\n",
      "long             21613 non-null float64\n",
      "sqft_living15    21613 non-null int64\n",
      "sqft_lot15       21613 non-null int64\n",
      "dtypes: float64(5), int64(13)\n",
      "memory usage: 3.0 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.161300e+04</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>2.161300e+04</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.400881e+05</td>\n",
       "      <td>3.370842</td>\n",
       "      <td>2.114757</td>\n",
       "      <td>2079.899736</td>\n",
       "      <td>1.510697e+04</td>\n",
       "      <td>1.494309</td>\n",
       "      <td>0.007542</td>\n",
       "      <td>0.234303</td>\n",
       "      <td>3.409430</td>\n",
       "      <td>7.656873</td>\n",
       "      <td>1788.390691</td>\n",
       "      <td>291.509045</td>\n",
       "      <td>1971.005136</td>\n",
       "      <td>84.402258</td>\n",
       "      <td>47.560053</td>\n",
       "      <td>-122.213896</td>\n",
       "      <td>1986.552492</td>\n",
       "      <td>12768.455652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.671272e+05</td>\n",
       "      <td>0.930062</td>\n",
       "      <td>0.770163</td>\n",
       "      <td>918.440897</td>\n",
       "      <td>4.142051e+04</td>\n",
       "      <td>0.539989</td>\n",
       "      <td>0.086517</td>\n",
       "      <td>0.766318</td>\n",
       "      <td>0.650743</td>\n",
       "      <td>1.175459</td>\n",
       "      <td>828.090978</td>\n",
       "      <td>442.575043</td>\n",
       "      <td>29.373411</td>\n",
       "      <td>401.679240</td>\n",
       "      <td>0.138564</td>\n",
       "      <td>0.140828</td>\n",
       "      <td>685.391304</td>\n",
       "      <td>27304.179631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>7.500000e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>290.000000</td>\n",
       "      <td>5.200000e+02</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>290.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1900.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>47.155900</td>\n",
       "      <td>-122.519000</td>\n",
       "      <td>399.000000</td>\n",
       "      <td>651.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.219500e+05</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>1427.000000</td>\n",
       "      <td>5.040000e+03</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1190.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1951.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>47.471000</td>\n",
       "      <td>-122.328000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>5100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.500000e+05</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>1910.000000</td>\n",
       "      <td>7.618000e+03</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1560.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1975.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>47.571800</td>\n",
       "      <td>-122.230000</td>\n",
       "      <td>1840.000000</td>\n",
       "      <td>7620.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.450000e+05</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2550.000000</td>\n",
       "      <td>1.068800e+04</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2210.000000</td>\n",
       "      <td>560.000000</td>\n",
       "      <td>1997.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>47.678000</td>\n",
       "      <td>-122.125000</td>\n",
       "      <td>2360.000000</td>\n",
       "      <td>10083.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.700000e+06</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>13540.000000</td>\n",
       "      <td>1.651359e+06</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>9410.000000</td>\n",
       "      <td>4820.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>47.777600</td>\n",
       "      <td>-121.315000</td>\n",
       "      <td>6210.000000</td>\n",
       "      <td>871200.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              price      bedrooms     bathrooms   sqft_living      sqft_lot  \\\n",
       "count  2.161300e+04  21613.000000  21613.000000  21613.000000  2.161300e+04   \n",
       "mean   5.400881e+05      3.370842      2.114757   2079.899736  1.510697e+04   \n",
       "std    3.671272e+05      0.930062      0.770163    918.440897  4.142051e+04   \n",
       "min    7.500000e+04      0.000000      0.000000    290.000000  5.200000e+02   \n",
       "25%    3.219500e+05      3.000000      1.750000   1427.000000  5.040000e+03   \n",
       "50%    4.500000e+05      3.000000      2.250000   1910.000000  7.618000e+03   \n",
       "75%    6.450000e+05      4.000000      2.500000   2550.000000  1.068800e+04   \n",
       "max    7.700000e+06     33.000000      8.000000  13540.000000  1.651359e+06   \n",
       "\n",
       "             floors    waterfront          view     condition         grade  \\\n",
       "count  21613.000000  21613.000000  21613.000000  21613.000000  21613.000000   \n",
       "mean       1.494309      0.007542      0.234303      3.409430      7.656873   \n",
       "std        0.539989      0.086517      0.766318      0.650743      1.175459   \n",
       "min        1.000000      0.000000      0.000000      1.000000      1.000000   \n",
       "25%        1.000000      0.000000      0.000000      3.000000      7.000000   \n",
       "50%        1.500000      0.000000      0.000000      3.000000      7.000000   \n",
       "75%        2.000000      0.000000      0.000000      4.000000      8.000000   \n",
       "max        3.500000      1.000000      4.000000      5.000000     13.000000   \n",
       "\n",
       "         sqft_above  sqft_basement      yr_built  yr_renovated           lat  \\\n",
       "count  21613.000000   21613.000000  21613.000000  21613.000000  21613.000000   \n",
       "mean    1788.390691     291.509045   1971.005136     84.402258     47.560053   \n",
       "std      828.090978     442.575043     29.373411    401.679240      0.138564   \n",
       "min      290.000000       0.000000   1900.000000      0.000000     47.155900   \n",
       "25%     1190.000000       0.000000   1951.000000      0.000000     47.471000   \n",
       "50%     1560.000000       0.000000   1975.000000      0.000000     47.571800   \n",
       "75%     2210.000000     560.000000   1997.000000      0.000000     47.678000   \n",
       "max     9410.000000    4820.000000   2015.000000   2015.000000     47.777600   \n",
       "\n",
       "               long  sqft_living15     sqft_lot15  \n",
       "count  21613.000000   21613.000000   21613.000000  \n",
       "mean    -122.213896    1986.552492   12768.455652  \n",
       "std        0.140828     685.391304   27304.179631  \n",
       "min     -122.519000     399.000000     651.000000  \n",
       "25%     -122.328000    1490.000000    5100.000000  \n",
       "50%     -122.230000    1840.000000    7620.000000  \n",
       "75%     -122.125000    2360.000000   10083.000000  \n",
       "max     -121.315000    6210.000000  871200.000000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape\n",
    "df.info()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se logra apreciar que en total hay 18 características en la tabla, y por lo tanto 18 columnas. Se observa además que hay 21613 filas (o datos), y que no existen datos nulos. Por otro lado, se tienen valores estadísticos para las distintas columnas tales como la media, el máximo, el mínimo, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "df_scaled = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay ciertos algoritmos de maquinas de aprendizaje que se ven beneficiados por esta accion. Por ejemplo, hay ciertos clasificadores que, si uno de sus atributos posee un gran  rango de valores, ciertas operaciones (como distancia euclidiana) se veran gobernadas por estos atributos, es decir, daran mas prioridad de la que merecen a estos. Otra razon es que ciertos metodos, como gradiente descendiente convergen mas rapido al normalizar. \n",
    "Para explicar la transformación aplicada, sería buena idea plasmar los datos en una gráfica antes y después de esta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD9CAYAAABX0LttAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21db9d2ada0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQJI6ZQBIUqcMAEnq1P8HSmpnzFctX7cAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21dbb790908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.hist(df_scaled['price'])\n",
    "plt.show()\n",
    "df_scaled['price'] = np.log(df['price'])\n",
    "df_scaled.head()\n",
    "plt.hist(df_scaled['price'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se logra apreciar el comportamiento exponencial negativo que poseen los datos incialmente, siendo además que se concentran en valores cercanos a 0. Al aplicar logaritmo a estos datos, se distribuyen de mejor manera y se les da más significancia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=False, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.linear_model as lm\n",
    "X = df_scaled.iloc[:,1:] #use .ix instead, in older pandas version #quita la columna price\n",
    "N = X.shape[0]\n",
    "X.insert(X.shape[1], 'intercept', np.ones(N))#inserta la columna 'intercept' con valor 1.0\n",
    "y = df_scaled['price']\n",
    "##mascara estatica con el 70% de los datos\n",
    "mascara = np.zeros(len(X))\n",
    "limit = int(len(X)*0.7)\n",
    "mascara[:limit] = 1\n",
    "istrain = mascara== 1\n",
    "Xtrain = X[istrain]\n",
    "ytrain = y[istrain]\n",
    "Xtest = X[np.logical_not(istrain)]\n",
    "ytest = y[np.logical_not(istrain)]\n",
    "linreg = lm.LinearRegression(fit_intercept = False)\n",
    "linreg.fit(Xtrain, ytrain)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El paso de la línea 4 se agrega debido a que el modelo lineal se define de la siguiente forma:\n",
    "$$ \\hat{y} = \\beta_0 + \\sum_{i=1}^{n} \\hat{\\beta_i} x_i  $$\n",
    "\n",
    "Donde $\\hat{\\beta_i}$ es el peso del i-esimo atributo, $x_i$ es el i-esimo atributo del input $x$ y $b_0$ es el intercepto.\n",
    "En modo vectorial esto se puede anotar como:\n",
    "$$ \\hat{y} = \\beta_0 +\\hat{\\beta}^T X $$\n",
    "\n",
    "A modo de notación y para simplicidad de operaciones, el vector $\\beta_0$ puede incluirse dentro del vector $\\hat{\\beta}^T$, siempre y cuando en la última posición del vector input $X$ se agrege un 1, de tal forma de que al multiplicarlos, se logre sumar $\\beta_0$.\n",
    "\n",
    "Los parametros que se le entregan a lm.LinearRegression son:\n",
    "\n",
    "- fit_intercept: por default es True. Si es False, significa que los datos ingresados ya estaran centrados\n",
    "- normalize: Por default es False. Si es True, los regresores seran normalizados\n",
    "- copy_X: por default es True. Si es True, X sera copieda. En caso contrario, sera sobreescrito\n",
    "- n_jobs: por default es 1. Es el numero de trabajos usados para computar\n",
    "\n",
    "El metodo fit recibe Xtrain e ytrain, quienes son la data de entrenamiento para la maquina (correspondiente al 70% de la data total). Xtrain posee todos los datos de las filas excepto el precio e ytrain posee el precio de cada fila asociada, dado que es la variable de estudio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gabri\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Atributos</th>\n",
       "      <th>Pesos</th>\n",
       "      <th>z-scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bedrooms</td>\n",
       "      <td>-0.008270</td>\n",
       "      <td>-3.034080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bathrooms</td>\n",
       "      <td>0.055960</td>\n",
       "      <td>14.656026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sqft_living</td>\n",
       "      <td>0.057769</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sqft_lot</td>\n",
       "      <td>0.022159</td>\n",
       "      <td>7.597490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>floors</td>\n",
       "      <td>0.037595</td>\n",
       "      <td>12.269887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>waterfront</td>\n",
       "      <td>0.033526</td>\n",
       "      <td>14.785692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>view</td>\n",
       "      <td>0.042082</td>\n",
       "      <td>17.390702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>condition</td>\n",
       "      <td>0.045277</td>\n",
       "      <td>20.536815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>grade</td>\n",
       "      <td>0.186212</td>\n",
       "      <td>48.068186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sqft_above</td>\n",
       "      <td>0.047130</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>sqft_basement</td>\n",
       "      <td>0.031699</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>yr_built</td>\n",
       "      <td>-0.109875</td>\n",
       "      <td>-33.790551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>yr_renovated</td>\n",
       "      <td>0.014798</td>\n",
       "      <td>6.889786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>lat</td>\n",
       "      <td>0.186277</td>\n",
       "      <td>85.795087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>long</td>\n",
       "      <td>-0.004079</td>\n",
       "      <td>-1.589882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>sqft_living15</td>\n",
       "      <td>0.085933</td>\n",
       "      <td>23.568652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>sqft_lot15</td>\n",
       "      <td>-0.007013</td>\n",
       "      <td>-2.346780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>intercept</td>\n",
       "      <td>13.039692</td>\n",
       "      <td>6220.415728</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Atributos      Pesos     z-scores\n",
       "0        bedrooms  -0.008270    -3.034080\n",
       "1       bathrooms   0.055960    14.656026\n",
       "2     sqft_living   0.057769          NaN\n",
       "3        sqft_lot   0.022159     7.597490\n",
       "4          floors   0.037595    12.269887\n",
       "5      waterfront   0.033526    14.785692\n",
       "6            view   0.042082    17.390702\n",
       "7       condition   0.045277    20.536815\n",
       "8           grade   0.186212    48.068186\n",
       "9      sqft_above   0.047130          NaN\n",
       "10  sqft_basement   0.031699          NaN\n",
       "11       yr_built  -0.109875   -33.790551\n",
       "12   yr_renovated   0.014798     6.889786\n",
       "13            lat   0.186277    85.795087\n",
       "14           long  -0.004079    -1.589882\n",
       "15  sqft_living15   0.085933    23.568652\n",
       "16     sqft_lot15  -0.007013    -2.346780\n",
       "17      intercept  13.039692  6220.415728"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de condicion:  8.16107406273e+15\n"
     ]
    }
   ],
   "source": [
    "def zscore(linreg,Xtrain,ytrain,c=1):   \n",
    "    z=[]\n",
    "    atributos=[]\n",
    "    predicciones = linreg.predict(Xtrain)\n",
    "\n",
    "    deltas = ytrain-predicciones   #y en la parte 1.d era la columna precio. Con istrain le aplico mascara pra selccionar datos\n",
    "    numerador1 = deltas.dot(deltas)\n",
    "    denominador1 = len(deltas) - len(linreg.coef_) - 1\n",
    "    theta = numerador1 /  denominador1\n",
    "    theta=theta**0.5\n",
    "\n",
    "    xt = np.transpose(Xtrain)\n",
    "    xtx = ( xt.dot(Xtrain) )\n",
    "    vjj = np.linalg.inv(xtx)\n",
    "\n",
    "    j=0\n",
    "    for i in linreg.coef_:\n",
    "        peso = i\n",
    "        z_score = i/( theta*( vjj[j][j] )**0.5 )\n",
    "        j+=1\n",
    "        z.append(z_score)\n",
    "        if c==1:\n",
    "            atributos.append(Xtrain.columns[j-1])\n",
    "    if c==1:\n",
    "        d = {'Atributos' : atributos,\n",
    "             'Pesos' : np.asarray(linreg.coef_),\n",
    "             'z-scores' : z}\n",
    "        matriz=pd.DataFrame(d)\n",
    "        display(matriz)\n",
    "        print(\"Numero de condicion: \",np.linalg.cond(Xtrain))#numero condicion matriz a\n",
    "    return z\n",
    "scores = zscore(linreg,Xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para encontrar el z-score se aplicó la siguiente ecuación:\n",
    "$$z-score=\\frac{\\hat{\\beta_j}}{\\hat{\\sigma}\\sqrt{\\hat{v}_{jj}}}$$\n",
    "En donde el $\\hat{\\beta_j}$ es el estimador del peso de cierto atributo, $\\hat{\\sigma}$ es la desviación estándar y $\\sqrt{\\hat{v}_{jj}}$ es el valor en la diagonal en la matriz de covarianzas del modelo.\n",
    "\n",
    "Se puede ver que hay valores de z-score que dan como resultado NaN (not a number). Esto se puede deber a las caracteristicas de la matriz Xtrain, la cual esta mal condicionada (su numero de condicion es significativamente mayor que 1). Este mal condicionamiento puede ser debido a que hay columnas (atributos) que son linealmnete dependientes (o muy cercanas a serlo) de otras. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmQAAAFBCAYAAADZmLOkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21dbc2d5470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (10, 5))\n",
    "plt.plot(Xtrain['sqft_living'],Xtrain['sqft_above'],'*')\n",
    "plt.xlabel('sqft_living')\n",
    "plt.ylabel('sqft_above')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se aprecia en la gráfica, se aprecia que las variables $\\textit{sqft_living}$ y $\\textit{sqft_above}$ están linealmente relacionadas. Para solucionar esto, se pueden quitar alguna de las columnas que poseen dependencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Atributos</th>\n",
       "      <th>Pesos</th>\n",
       "      <th>z-scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bedrooms</td>\n",
       "      <td>-0.008270</td>\n",
       "      <td>-3.034180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bathrooms</td>\n",
       "      <td>0.055960</td>\n",
       "      <td>14.656511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sqft_lot</td>\n",
       "      <td>0.022159</td>\n",
       "      <td>7.597741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>floors</td>\n",
       "      <td>0.037595</td>\n",
       "      <td>12.270293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>waterfront</td>\n",
       "      <td>0.033526</td>\n",
       "      <td>14.786181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>view</td>\n",
       "      <td>0.042082</td>\n",
       "      <td>17.391277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>condition</td>\n",
       "      <td>0.045277</td>\n",
       "      <td>20.537495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>grade</td>\n",
       "      <td>0.186212</td>\n",
       "      <td>48.069777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sqft_above</td>\n",
       "      <td>0.099216</td>\n",
       "      <td>21.085966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sqft_basement</td>\n",
       "      <td>0.059536</td>\n",
       "      <td>20.667375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>yr_built</td>\n",
       "      <td>-0.109875</td>\n",
       "      <td>-33.791670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>yr_renovated</td>\n",
       "      <td>0.014798</td>\n",
       "      <td>6.890014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>lat</td>\n",
       "      <td>0.186277</td>\n",
       "      <td>85.797926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>long</td>\n",
       "      <td>-0.004079</td>\n",
       "      <td>-1.589935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>sqft_living15</td>\n",
       "      <td>0.085933</td>\n",
       "      <td>23.569432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>sqft_lot15</td>\n",
       "      <td>-0.007013</td>\n",
       "      <td>-2.346857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>intercept</td>\n",
       "      <td>13.039692</td>\n",
       "      <td>6220.621563</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Atributos      Pesos     z-scores\n",
       "0        bedrooms  -0.008270    -3.034180\n",
       "1       bathrooms   0.055960    14.656511\n",
       "2        sqft_lot   0.022159     7.597741\n",
       "3          floors   0.037595    12.270293\n",
       "4      waterfront   0.033526    14.786181\n",
       "5            view   0.042082    17.391277\n",
       "6       condition   0.045277    20.537495\n",
       "7           grade   0.186212    48.069777\n",
       "8      sqft_above   0.099216    21.085966\n",
       "9   sqft_basement   0.059536    20.667375\n",
       "10       yr_built  -0.109875   -33.791670\n",
       "11   yr_renovated   0.014798     6.890014\n",
       "12            lat   0.186277    85.797926\n",
       "13           long  -0.004079    -1.589935\n",
       "14  sqft_living15   0.085933    23.569432\n",
       "15     sqft_lot15  -0.007013    -2.346857\n",
       "16      intercept  13.039692  6220.621563"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de condicion:  5.68782366052\n"
     ]
    }
   ],
   "source": [
    "Xtrain2=Xtrain.drop(['sqft_living'],axis=1,inplace=False)\n",
    "linreg2 = lm.LinearRegression(fit_intercept = False)\n",
    "linreg2.fit(Xtrain2, ytrain)\n",
    "\n",
    "scores2=zscore(linreg2,Xtrain2,ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_test = linreg.predict(Xtest)\n",
    "mse_test = np.mean(np.power(yhat_test - ytest, 2))\n",
    "Xm = Xtrain.as_matrix()\n",
    "ym = ytrain.as_matrix()\n",
    "from sklearn.model_selection import KFold\n",
    "##Para 10 Folds\n",
    "kf = KFold(n_splits=10)\n",
    "mse_cv10 = 0\n",
    "for train, val in kf.split(Xm):\n",
    "    linreg = lm.LinearRegression(fit_intercept = False)\n",
    "    linreg.fit(Xm[train], ym[train])\n",
    "    yhat_val = linreg.predict(Xm[val])\n",
    "    mse_fold = np.mean(np.power(yhat_val - ym[val], 2))\n",
    "    mse_cv10 += mse_fold\n",
    "mse_cv10 = mse_cv10 / 10\n",
    "##Para 5 Folds\n",
    "kf = KFold(n_splits=5)\n",
    "mse_cv5 = 0\n",
    "for train, val in kf.split(Xm):\n",
    "    linreg = lm.LinearRegression(fit_intercept = False)\n",
    "    linreg.fit(Xm[train], ym[train])\n",
    "    yhat_val = linreg.predict(Xm[val])\n",
    "    mse_fold = np.mean(np.power(yhat_val - ym[val], 2))\n",
    "    mse_cv5 += mse_fold\n",
    "mse_cv5 = mse_cv5 / 5\n",
    "\n",
    "print ('Error real (sin validación):',mse_test)\n",
    "print ('Error de validación (10 folds):',mse_cv10)\n",
    "print ('Error de validación (5 folds):',mse_cv5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al observar los errores se logra apreciar que utilizar 10 folds de cross validation disminuye el error de predicción comparado con los otros métodos (con menos folds). Por otro lado, utilizar validación disminuye el error en comparación a sólo utilizar el conjunto de pruebas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pylab\n",
    "import scipy.stats as stats\n",
    "yhat = linreg.predict(Xtrain)\n",
    "\n",
    "diferencias = ytrain - yhat\n",
    "\n",
    "plt.figure(figsize = (16, 5))\n",
    "stats.probplot(diferencias, dist=\"norm\", plot=pylab)\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es razonable la hipótesis de normalidad dado que los datos se adecuan en gran medida a la distribución normal. Los datos que se escapan sólo yacen en los extremos y no son la concentración de estos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pregunta 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def fss(x, y, names_x, k = 10000):\n",
    "    X = Xtest.as_matrix()\n",
    "    Y= ytest.as_matrix()\n",
    "    train_err=[]\n",
    "    test_err=[]\n",
    "    p = x.shape[1]-1 #cantidad de atributos \n",
    "    k = min(p, k) #maxima cantidad de atributos elegidos\n",
    "    names_x = np.array(names_x) #nombres de los atributos\n",
    "    remaining = list(range(0, p)) \n",
    "    selected = [p]\n",
    "    current_score = best_new_score = 0.0\n",
    "    while remaining and len(selected)<=k : #mientras queden atributos por agregar y no se supere el maximo\n",
    "        score_candidates = []\n",
    "        for candidate in remaining:\n",
    "            model = lm.LinearRegression(fit_intercept=False)\n",
    "            indexes = selected + [candidate] #atriubtos que son los mejores + un atributo de los que queda\n",
    "            x_train = x[:,indexes]\n",
    "            X_test = X[:,indexes]\n",
    "            \n",
    "            predictions_train = model.fit(x_train, y).predict(x_train)\n",
    "            \n",
    "            scores=map(abs,zscore(model,x_train,y,0))\n",
    "            puntaje=sum(scores)\n",
    "            \n",
    "            residuals_train = predictions_train - y\n",
    "            mse_candidate = (residuals_train.dot(residuals_train)/len(residuals_train))**0.5\n",
    "            \n",
    "            predictions_test = model.predict(X_test)\n",
    "            residuals_test = predictions_test - Y\n",
    "            err = (residuals_test.dot(residuals_test)/len(residuals_test))**0.5\n",
    "            \n",
    "            score_candidates.append((puntaje, mse_candidate, candidate, err)) #arma una tupla con el error y el candidato\n",
    "            \n",
    "        score_candidates.sort() #ordena por los errores mas chicos\n",
    "        score_candidates.reverse()\n",
    "        #score_candidates[:] = score_candidates[::-1] #invierte la lista\n",
    "        best_puntaje, best_new_score, best_candidate,best_test_score = score_candidates[0]#.pop() #saca el mejor atributo (esta al final de la lista)\n",
    "        remaining.remove(best_candidate)\n",
    "        selected.append(best_candidate)\n",
    "        train_err.append((len(selected),best_new_score))\n",
    "        test_err.append((len(selected),best_test_score))\n",
    "        print (\"selected = %s ...\"%names_x[best_candidate])\n",
    "        print (\"totalvars=%d, mse = %f\"%(len(indexes),best_new_score))\n",
    "    return selected,train_err,test_err\n",
    "names_regressors = X.columns[:-1] #without intercept\n",
    "selec,train,test=fss(Xm,ym,names_regressors)\n",
    "train.sort()\n",
    "test.sort()\n",
    "plt.figure(figsize = (16, 5))\n",
    "plt.xlabel('Cantidad de Atributos')\n",
    "plt.ylabel('Error')\n",
    "plt.plot([i[0] for i in train],[i[1] for i in train], '*-')\n",
    "plt.plot([i[0] for i in test],[i[1] for i in test], '*-')\n",
    "plt.legend(['Entrenamiento','Prueba'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El método utilizado para seleccionar atributos se basó en seleccionar el atributo que producía una mayor sumatoria de los z-score totales resultantes del entrenamiento. De esa forma se maximizaba el z-score del modelo en cada iteración."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pregunta 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#se grafica los pesos que se da a cada parametro variando el lambda--->alpha\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "import matplotlib.pylab as plt\n",
    "X2 = X.drop('intercept', axis=1,inplace=False)  #quita el intercepto\n",
    "Xtrain = X2[istrain]\n",
    "ytrain = y[istrain]\n",
    "names_regressors = X2.columns\n",
    "alphas_ = np.logspace(7,1,base=10)\n",
    "coefs = []\n",
    "model = Ridge(fit_intercept=True,solver='svd')  #pide que la regresion tome en cuenta el intercepto desde dentro\n",
    "for a in alphas_:\n",
    "    model.set_params(alpha=a)\n",
    "    model.fit(Xtrain, ytrain)\n",
    "    coefs.append(model.coef_)\n",
    "plt.figure(figsize = (16,9))\n",
    "ax = plt.gca()\n",
    "for y_arr, label in zip(np.squeeze(coefs).T, names_regressors):\n",
    "    plt.plot(alphas_, y_arr, label=label)\n",
    "plt.legend()\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlim(ax.get_xlim()[::-1]) # reverse axis\n",
    "plt.title('Regularization Path RIDGE')\n",
    "plt.axis('tight')\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "import matplotlib.pylab as plt\n",
    "X2 = X.drop('intercept', axis=1,inplace=False)  #quita el intercepto\n",
    "Xtrain = X2[istrain]\n",
    "ytrain = y[istrain]\n",
    "names_regressors = X2.columns\n",
    "alphas_ = np.logspace(0,-3,base=10)\n",
    "coefs = []\n",
    "model = Lasso(fit_intercept=True)\n",
    "for a in alphas_:\n",
    "    model.set_params(alpha=a)\n",
    "    model.fit(Xtrain, ytrain)\n",
    "    coefs.append(model.coef_)\n",
    "plt.figure(figsize = (16,9))\n",
    "ax = plt.gca()\n",
    "for y_arr, label in zip(np.squeeze(coefs).T, names_regressors):\n",
    "    plt.plot(alphas_, y_arr, label=label)\n",
    "plt.legend()\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlim(ax.get_xlim()[::-1]) # reverse axis\n",
    "plt.title('Regularization Path LASSO')\n",
    "plt.axis('tight')\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest = X2[np.logical_not(istrain)]\n",
    "ytest = y[np.logical_not(istrain)]\n",
    "alphas_ = #choose it\n",
    "coefs = []\n",
    "model = #choose it\n",
    "mse_test = []\n",
    "mse_train = []\n",
    "for a in alphas_:\n",
    "    model.set_params(alpha=a)\n",
    "    model.fit(Xtrain, ytrain)\n",
    "    yhat_train = model.predict(Xtrain)\n",
    "    yhat_test = model.predict(Xtest)\n",
    "    mse_train.append(np.mean(np.power(yhat_train - ytrain, 2)))\n",
    "    mse_test.append(np.mean(np.power(yhat_test - ytest, 2)))\n",
    "ax = plt.gca()\n",
    "ax.plot(alphas_,mse_train,label='train error ridge')\n",
    "ax.plot(alphas_,mse_test,label='test error ridge')\n",
    "plt.legend(loc=1)\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlim(ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 3.d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MSE(y,yhat): return np.mean(np.power(y-yhat,2))\n",
    "Xm = Xtrain.as_matrix()\n",
    "ym = ytrain.as_matrix()\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=10)\n",
    "best_cv_mse = float(\"inf\")\n",
    "model = #choose it\n",
    "alphas_ = #alphas to evaluate\n",
    "for a in alphas_:\n",
    "    model.set_params(alpha=a)\n",
    "    mse_list_k10 = [MSE(model.fit(Xm[train], ym[train]).predict(Xm[val]), ym[val]) \\\n",
    "        for train, val in kf.split(Xm)]\n",
    "    if np.mean(mse_list_k10) < best_cv_mse:\n",
    "        best_cv_mse = np.mean(mse_list_k10)\n",
    "        best_alpha = a\n",
    "        print \"BEST PARAMETER=%f, MSE(CV)=%f\"%(best_alpha,best_cv_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pregunta 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_A = df_scaled.sample(1000,random_state=11)\n",
    "\n",
    "frames = []\n",
    "valor = df_scaled.price\n",
    "length = 0.3\n",
    "for z in np.arange(int(np.min(valor)),int(np.max(valor))+1,length):\n",
    "    #un maximo de 100 datos por intervalo\n",
    "    aux = df_scaled[(df_scaled.price >= z) & (df_scaled.price < z+length)].head(100)\n",
    "    frames.append(aux)\n",
    "df_B = pd.concat(frames).sample(1000,random_state=11) #crea el dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_A = df_A.iloc[:,1:].values\n",
    "y_A = df_A.price\n",
    "X_B = df_B.iloc[:,1:].values\n",
    "y_B = df_B.price\n",
    "from sklearn.model_selection import train_test_split\n",
    "Xtrain_A,Xval_A,ytrain_A,yval_A = train_test_split(X_A, y_A, test_size=0.3, random_state=42)\n",
    "Xtrain_B,Xval_B,ytrain_B,yval_B = train_test_split(X_B, y_B, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SE CREAN Y ENTRENENAN LOS MODELOS\n",
    "modA = lm.LinearRegression(fit_intercept = True)\n",
    "modB = lm.LinearRegression(fit_intercept = True)\n",
    "\n",
    "modA.fit(Xtrain_A,ytrain_A)\n",
    "modB.fit(Xtrain_B,ytrain_B)\n",
    "\n",
    "#CADA MODELO PREDICE SU CONJUNTO DE VALIDACION\n",
    "valpredA_A = modA.predict(Xval_A)\n",
    "valpredB_B = modB.predict(Xval_B)\n",
    "\n",
    "#CADA MODELO PREDICE EL OTRO CONJUNTO DE VALIDACION\n",
    "valpredA_B = modA.predict(Xval_B)\n",
    "valpredB_A = modB.predict(Xval_A)\n",
    "\n",
    "#DIFERENCIAS DE LAS PREDICCIONES CON EL VALOR REAL\n",
    "deltaA_A = valpredA_A - yval_A\n",
    "deltaB_B = valpredB_B - yval_B\n",
    "\n",
    "deltaA_B = valpredA_B - yval_B\n",
    "deltaB_A = valpredB_A - yval_A\n",
    "\n",
    "#SE CALCULA LA SUMA DE LAS DIFERENCIAS AL CUADRADO\n",
    "errorA_A = deltaA_A.dot(deltaA_A) /len(deltaA_A)\n",
    "errorB_B = deltaB_B.dot(deltaB_B) /len(deltaB_B)\n",
    "\n",
    "\n",
    "errorA_B = deltaA_B.dot(deltaA_B) /len(deltaA_B)\n",
    "errorB_A = deltaB_A.dot(deltaB_A) /len(deltaB_A)\n",
    "\n",
    "#SE IMPRIMEN\n",
    "print(\"Error del modelo A con validación de A:\",errorA_A)\n",
    "print(\"Error del modelo B con validación de B:\",errorB_B)\n",
    "\n",
    "print(\"Error del modelo A con validación de B:\",errorA_B)\n",
    "print(\"Error del modelo B con validación de A:\",errorB_A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se logra apreciar que el error para la muestra A con su mismo conjunto de validación es el menor de todos los errores presentes dado que su distribución es más normal. Luego, ambos modelos (A como B) presentan un error más alto al utilizar el conjunto de validación B, siendo el del modelo B menor entre estos. Lo anterior se debe a que se están probado datos de validación con una distribución más cercana a la cual se entrenó el modelo. Por último, el modelo B con validación A presenta un error bajo en comparación a los validados con B, pero es mayor que al validar con A dado que los datos presentan una distribución más uniforme."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Eligiriamos el modelo A, dado que los datos se encuentran mejor distribuidos para el análisis que se le realiza (y dado también que presentan un error menor como vimos en la pregunta 4.b). Esta distribución disminuye el sesgo existente, lo que termina ajustando el mejor médida el modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pregunta 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "headers = ['age','sex','chest_pain','blood_p','serum','blood_s','electro','max_heart', \\\n",
    "'angina','oldpeak','slope','vessel','thal','normal']\n",
    "dataset = 'heart.dat'\n",
    "df = pd.read_csv(dataset, header=None, names=headers, sep=' ')\n",
    "#create your matrix\n",
    "df.head()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(df, test_size=0.3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print \"Score: \"%(accuracy_score(y_outlier,y_predict_outlier)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
